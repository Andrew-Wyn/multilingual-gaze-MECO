{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "42043c06",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import collections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dd436b65",
   "metadata": {},
   "outputs": [],
   "source": [
    "def collect_losses(root_dir):\n",
    "\n",
    "    depth = 2\n",
    "\n",
    "    seeds = [123, 456, 789]\n",
    "\n",
    "    dict_res = dict() # {\"dataset_name\" : [means stats, var stats]}\n",
    "\n",
    "    # collect ts losses\n",
    "\n",
    "    for seed_ in seeds:\n",
    "        seed_rootdir = f\"{root_dir}/{seed_}\"\n",
    "\n",
    "        for subdir, dirs, files in os.walk(seed_rootdir):\n",
    "            if subdir[len(seed_rootdir):].count(os.sep) < depth:\n",
    "                for file_ in files:\n",
    "                    if file_ == \"finetuning_results.json\":\n",
    "                        with open(subdir + \"/\" + file_) as f:\n",
    "                            d = json.load(f)\n",
    "                            losses_ts = list(d[\"losses_ts\"].values())\n",
    "\n",
    "                        dataset_name = subdir.split(os.sep)[-1]\n",
    "                        if dataset_name in dict_res.keys():\n",
    "                            dict_res[dataset_name].append(losses_ts)\n",
    "                        else:\n",
    "                            dict_res[dataset_name] = [losses_ts]\n",
    "\n",
    "    # compute mean and std for each losses\n",
    "\n",
    "    for dataset, losses_list in dict_res.items():\n",
    "        means = []\n",
    "        stds = []\n",
    "\n",
    "        losses_len = len(losses_list[0])\n",
    "        for i in range(losses_len):\n",
    "            losses_i = []\n",
    "            for losses in losses_list:\n",
    "                losses_i.append(losses[i])\n",
    "            means.append(np.mean(losses_i))\n",
    "            stds.append(np.std(losses_i))\n",
    "\n",
    "        dict_res[dataset] = [means, stds]\n",
    "\n",
    "    return dict_res\n",
    "\n",
    "\n",
    "def avg_losses_over_datasets(datasets_losses):\n",
    "    avg_losses_dts = None\n",
    "\n",
    "    num_dts = 0\n",
    "\n",
    "    for dataset, mean_std in datasets_losses.items():\n",
    "        means = mean_std[0]\n",
    "\n",
    "        if avg_losses_dts is None:\n",
    "            avg_losses_dts = np.array(means)\n",
    "        else:\n",
    "            avg_losses_dts += np.array(means)\n",
    "\n",
    "        num_dts += 1\n",
    "\n",
    "    return avg_losses_dts / num_dts\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2ebf993f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def collect_mean_baseline(root_dir):\n",
    "    dict_res_mae = dict()\n",
    "    dict_res_mse = dict()\n",
    "\n",
    "    for subdir, dirs, files in os.walk(root_dir):\n",
    "        for file_ in files:\n",
    "            with open(subdir + \"/\" + file_) as f:\n",
    "                d = json.load(f)\n",
    "                dict_res_mae[file_.split(\".\")[0]] = dict()\n",
    "                dict_res_mse[file_.split(\".\")[0]] = dict()\n",
    "                \n",
    "                for k, v in d.items():\n",
    "                    if \"mae\" in k:\n",
    "                        dict_res_mae[file_.split(\".\")[0]][k] = v\n",
    "                    else:\n",
    "                        dict_res_mse[file_.split(\".\")[0]][k] = v\n",
    "                \n",
    "\n",
    "    return dict_res_mae, dict_res_mse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "552ffaf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "res_mae, res_mse = collect_mean_baseline(\"../mean_baseline\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "dcf96ee5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mae_loss0</th>\n",
       "      <th>mae_loss1</th>\n",
       "      <th>mae_loss2</th>\n",
       "      <th>mae_loss3</th>\n",
       "      <th>mae_loss4</th>\n",
       "      <th>mae_loss5</th>\n",
       "      <th>mae_loss6</th>\n",
       "      <th>mae_loss7</th>\n",
       "      <th>mae_loss_all</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>mean_baseline_results_ge_2</th>\n",
       "      <td>23.631326</td>\n",
       "      <td>14.618062</td>\n",
       "      <td>7.006784</td>\n",
       "      <td>8.147557</td>\n",
       "      <td>7.051513</td>\n",
       "      <td>7.868829</td>\n",
       "      <td>18.587370</td>\n",
       "      <td>17.797943</td>\n",
       "      <td>13.088672</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean_baseline_results_en_1</th>\n",
       "      <td>38.517199</td>\n",
       "      <td>14.621716</td>\n",
       "      <td>10.738502</td>\n",
       "      <td>11.030411</td>\n",
       "      <td>13.813458</td>\n",
       "      <td>11.517820</td>\n",
       "      <td>18.290697</td>\n",
       "      <td>17.886902</td>\n",
       "      <td>17.052091</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean_baseline_results_sp_1</th>\n",
       "      <td>38.517199</td>\n",
       "      <td>14.621716</td>\n",
       "      <td>10.738502</td>\n",
       "      <td>11.030411</td>\n",
       "      <td>13.813458</td>\n",
       "      <td>11.517820</td>\n",
       "      <td>18.290697</td>\n",
       "      <td>17.886902</td>\n",
       "      <td>17.052091</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean_baseline_results_sp_0</th>\n",
       "      <td>24.549716</td>\n",
       "      <td>14.705048</td>\n",
       "      <td>11.912802</td>\n",
       "      <td>11.594023</td>\n",
       "      <td>12.410025</td>\n",
       "      <td>13.139339</td>\n",
       "      <td>16.958553</td>\n",
       "      <td>22.415786</td>\n",
       "      <td>15.960663</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean_baseline_results_en_0</th>\n",
       "      <td>24.549716</td>\n",
       "      <td>14.705048</td>\n",
       "      <td>11.912802</td>\n",
       "      <td>11.594023</td>\n",
       "      <td>12.410025</td>\n",
       "      <td>13.139339</td>\n",
       "      <td>16.958553</td>\n",
       "      <td>22.415786</td>\n",
       "      <td>15.960663</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean_baseline_results_en_all</th>\n",
       "      <td>21.930317</td>\n",
       "      <td>17.845610</td>\n",
       "      <td>8.207685</td>\n",
       "      <td>6.764501</td>\n",
       "      <td>9.042601</td>\n",
       "      <td>7.670029</td>\n",
       "      <td>12.825503</td>\n",
       "      <td>13.182144</td>\n",
       "      <td>12.183550</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean_baseline_results_it_2</th>\n",
       "      <td>26.582837</td>\n",
       "      <td>16.653791</td>\n",
       "      <td>6.200814</td>\n",
       "      <td>4.721693</td>\n",
       "      <td>6.028809</td>\n",
       "      <td>6.263821</td>\n",
       "      <td>22.267081</td>\n",
       "      <td>17.077490</td>\n",
       "      <td>13.224541</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean_baseline_results_it_1</th>\n",
       "      <td>48.835523</td>\n",
       "      <td>14.575395</td>\n",
       "      <td>9.585082</td>\n",
       "      <td>7.415826</td>\n",
       "      <td>13.107302</td>\n",
       "      <td>6.873666</td>\n",
       "      <td>10.576857</td>\n",
       "      <td>26.213612</td>\n",
       "      <td>17.147907</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean_baseline_results_sp_all</th>\n",
       "      <td>24.260191</td>\n",
       "      <td>16.306235</td>\n",
       "      <td>11.068098</td>\n",
       "      <td>11.078702</td>\n",
       "      <td>11.807236</td>\n",
       "      <td>13.443232</td>\n",
       "      <td>16.177630</td>\n",
       "      <td>18.831468</td>\n",
       "      <td>15.371598</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean_baseline_results_en_2</th>\n",
       "      <td>29.188814</td>\n",
       "      <td>12.345532</td>\n",
       "      <td>9.174236</td>\n",
       "      <td>8.970618</td>\n",
       "      <td>8.856351</td>\n",
       "      <td>9.950365</td>\n",
       "      <td>28.189191</td>\n",
       "      <td>28.300166</td>\n",
       "      <td>16.871909</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean_baseline_results_sp_2</th>\n",
       "      <td>29.188814</td>\n",
       "      <td>12.345532</td>\n",
       "      <td>9.174236</td>\n",
       "      <td>8.970618</td>\n",
       "      <td>8.856351</td>\n",
       "      <td>9.950365</td>\n",
       "      <td>28.189191</td>\n",
       "      <td>28.300166</td>\n",
       "      <td>16.871909</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean_baseline_results_it_0</th>\n",
       "      <td>27.637391</td>\n",
       "      <td>13.672727</td>\n",
       "      <td>10.621565</td>\n",
       "      <td>8.454745</td>\n",
       "      <td>10.162477</td>\n",
       "      <td>5.639922</td>\n",
       "      <td>32.291842</td>\n",
       "      <td>28.094448</td>\n",
       "      <td>17.071889</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean_baseline_results_it_all</th>\n",
       "      <td>23.974268</td>\n",
       "      <td>16.707821</td>\n",
       "      <td>7.636965</td>\n",
       "      <td>6.021734</td>\n",
       "      <td>7.362190</td>\n",
       "      <td>6.447346</td>\n",
       "      <td>19.871204</td>\n",
       "      <td>15.961751</td>\n",
       "      <td>12.997910</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean_baseline_results_ge_0</th>\n",
       "      <td>22.531274</td>\n",
       "      <td>9.740155</td>\n",
       "      <td>6.529791</td>\n",
       "      <td>4.171227</td>\n",
       "      <td>6.328743</td>\n",
       "      <td>5.068774</td>\n",
       "      <td>31.572468</td>\n",
       "      <td>31.625938</td>\n",
       "      <td>14.696046</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean_baseline_results_ge_all</th>\n",
       "      <td>18.694247</td>\n",
       "      <td>12.731371</td>\n",
       "      <td>6.202895</td>\n",
       "      <td>7.124132</td>\n",
       "      <td>6.360705</td>\n",
       "      <td>7.494808</td>\n",
       "      <td>20.444144</td>\n",
       "      <td>15.639329</td>\n",
       "      <td>11.836453</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean_baseline_results_ge_1</th>\n",
       "      <td>18.748651</td>\n",
       "      <td>11.024958</td>\n",
       "      <td>5.789866</td>\n",
       "      <td>5.935014</td>\n",
       "      <td>5.980459</td>\n",
       "      <td>6.198230</td>\n",
       "      <td>23.119222</td>\n",
       "      <td>15.254506</td>\n",
       "      <td>11.506362</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                              mae_loss0  mae_loss1  mae_loss2  mae_loss3  \\\n",
       "mean_baseline_results_ge_2    23.631326  14.618062   7.006784   8.147557   \n",
       "mean_baseline_results_en_1    38.517199  14.621716  10.738502  11.030411   \n",
       "mean_baseline_results_sp_1    38.517199  14.621716  10.738502  11.030411   \n",
       "mean_baseline_results_sp_0    24.549716  14.705048  11.912802  11.594023   \n",
       "mean_baseline_results_en_0    24.549716  14.705048  11.912802  11.594023   \n",
       "mean_baseline_results_en_all  21.930317  17.845610   8.207685   6.764501   \n",
       "mean_baseline_results_it_2    26.582837  16.653791   6.200814   4.721693   \n",
       "mean_baseline_results_it_1    48.835523  14.575395   9.585082   7.415826   \n",
       "mean_baseline_results_sp_all  24.260191  16.306235  11.068098  11.078702   \n",
       "mean_baseline_results_en_2    29.188814  12.345532   9.174236   8.970618   \n",
       "mean_baseline_results_sp_2    29.188814  12.345532   9.174236   8.970618   \n",
       "mean_baseline_results_it_0    27.637391  13.672727  10.621565   8.454745   \n",
       "mean_baseline_results_it_all  23.974268  16.707821   7.636965   6.021734   \n",
       "mean_baseline_results_ge_0    22.531274   9.740155   6.529791   4.171227   \n",
       "mean_baseline_results_ge_all  18.694247  12.731371   6.202895   7.124132   \n",
       "mean_baseline_results_ge_1    18.748651  11.024958   5.789866   5.935014   \n",
       "\n",
       "                              mae_loss4  mae_loss5  mae_loss6  mae_loss7  \\\n",
       "mean_baseline_results_ge_2     7.051513   7.868829  18.587370  17.797943   \n",
       "mean_baseline_results_en_1    13.813458  11.517820  18.290697  17.886902   \n",
       "mean_baseline_results_sp_1    13.813458  11.517820  18.290697  17.886902   \n",
       "mean_baseline_results_sp_0    12.410025  13.139339  16.958553  22.415786   \n",
       "mean_baseline_results_en_0    12.410025  13.139339  16.958553  22.415786   \n",
       "mean_baseline_results_en_all   9.042601   7.670029  12.825503  13.182144   \n",
       "mean_baseline_results_it_2     6.028809   6.263821  22.267081  17.077490   \n",
       "mean_baseline_results_it_1    13.107302   6.873666  10.576857  26.213612   \n",
       "mean_baseline_results_sp_all  11.807236  13.443232  16.177630  18.831468   \n",
       "mean_baseline_results_en_2     8.856351   9.950365  28.189191  28.300166   \n",
       "mean_baseline_results_sp_2     8.856351   9.950365  28.189191  28.300166   \n",
       "mean_baseline_results_it_0    10.162477   5.639922  32.291842  28.094448   \n",
       "mean_baseline_results_it_all   7.362190   6.447346  19.871204  15.961751   \n",
       "mean_baseline_results_ge_0     6.328743   5.068774  31.572468  31.625938   \n",
       "mean_baseline_results_ge_all   6.360705   7.494808  20.444144  15.639329   \n",
       "mean_baseline_results_ge_1     5.980459   6.198230  23.119222  15.254506   \n",
       "\n",
       "                              mae_loss_all  \n",
       "mean_baseline_results_ge_2       13.088672  \n",
       "mean_baseline_results_en_1       17.052091  \n",
       "mean_baseline_results_sp_1       17.052091  \n",
       "mean_baseline_results_sp_0       15.960663  \n",
       "mean_baseline_results_en_0       15.960663  \n",
       "mean_baseline_results_en_all     12.183550  \n",
       "mean_baseline_results_it_2       13.224541  \n",
       "mean_baseline_results_it_1       17.147907  \n",
       "mean_baseline_results_sp_all     15.371598  \n",
       "mean_baseline_results_en_2       16.871909  \n",
       "mean_baseline_results_sp_2       16.871909  \n",
       "mean_baseline_results_it_0       17.071889  \n",
       "mean_baseline_results_it_all     12.997910  \n",
       "mean_baseline_results_ge_0       14.696046  \n",
       "mean_baseline_results_ge_all     11.836453  \n",
       "mean_baseline_results_ge_1       11.506362  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(res_mae).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "41a57325",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mse_loss0</th>\n",
       "      <th>mse_loss1</th>\n",
       "      <th>mse_loss2</th>\n",
       "      <th>mse_loss3</th>\n",
       "      <th>mse_loss4</th>\n",
       "      <th>mse_loss5</th>\n",
       "      <th>mse_loss6</th>\n",
       "      <th>mse_loss7</th>\n",
       "      <th>mse_loss_all</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>mean_baseline_results_ge_2</th>\n",
       "      <td>806.651550</td>\n",
       "      <td>343.989716</td>\n",
       "      <td>83.463081</td>\n",
       "      <td>132.983429</td>\n",
       "      <td>84.457062</td>\n",
       "      <td>121.285454</td>\n",
       "      <td>651.978821</td>\n",
       "      <td>530.145752</td>\n",
       "      <td>344.369354</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean_baseline_results_en_1</th>\n",
       "      <td>1810.848999</td>\n",
       "      <td>274.370972</td>\n",
       "      <td>149.066116</td>\n",
       "      <td>168.991058</td>\n",
       "      <td>254.935638</td>\n",
       "      <td>201.284912</td>\n",
       "      <td>563.093567</td>\n",
       "      <td>598.750977</td>\n",
       "      <td>502.667816</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean_baseline_results_sp_1</th>\n",
       "      <td>1810.848999</td>\n",
       "      <td>274.370972</td>\n",
       "      <td>149.066116</td>\n",
       "      <td>168.991058</td>\n",
       "      <td>254.935638</td>\n",
       "      <td>201.284912</td>\n",
       "      <td>563.093567</td>\n",
       "      <td>598.750977</td>\n",
       "      <td>502.667816</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean_baseline_results_sp_0</th>\n",
       "      <td>811.969116</td>\n",
       "      <td>304.091217</td>\n",
       "      <td>217.723511</td>\n",
       "      <td>218.394775</td>\n",
       "      <td>229.068481</td>\n",
       "      <td>264.102142</td>\n",
       "      <td>449.343048</td>\n",
       "      <td>713.752563</td>\n",
       "      <td>401.055634</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean_baseline_results_en_0</th>\n",
       "      <td>811.969116</td>\n",
       "      <td>304.091217</td>\n",
       "      <td>217.723511</td>\n",
       "      <td>218.394775</td>\n",
       "      <td>229.068481</td>\n",
       "      <td>264.102142</td>\n",
       "      <td>449.343048</td>\n",
       "      <td>713.752563</td>\n",
       "      <td>401.055634</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean_baseline_results_en_all</th>\n",
       "      <td>640.336487</td>\n",
       "      <td>448.258118</td>\n",
       "      <td>100.318092</td>\n",
       "      <td>71.553055</td>\n",
       "      <td>116.193436</td>\n",
       "      <td>89.375259</td>\n",
       "      <td>273.781036</td>\n",
       "      <td>289.469513</td>\n",
       "      <td>253.660629</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean_baseline_results_it_2</th>\n",
       "      <td>984.338318</td>\n",
       "      <td>389.863342</td>\n",
       "      <td>61.180115</td>\n",
       "      <td>36.295246</td>\n",
       "      <td>59.142437</td>\n",
       "      <td>63.611099</td>\n",
       "      <td>746.830872</td>\n",
       "      <td>433.831909</td>\n",
       "      <td>346.886658</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean_baseline_results_it_1</th>\n",
       "      <td>2473.706543</td>\n",
       "      <td>266.036621</td>\n",
       "      <td>119.365463</td>\n",
       "      <td>87.648254</td>\n",
       "      <td>209.708557</td>\n",
       "      <td>83.170052</td>\n",
       "      <td>452.522308</td>\n",
       "      <td>1166.272705</td>\n",
       "      <td>607.303833</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean_baseline_results_sp_all</th>\n",
       "      <td>757.955078</td>\n",
       "      <td>360.768005</td>\n",
       "      <td>173.150589</td>\n",
       "      <td>188.085358</td>\n",
       "      <td>193.072662</td>\n",
       "      <td>268.179321</td>\n",
       "      <td>382.582245</td>\n",
       "      <td>512.253784</td>\n",
       "      <td>354.505920</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean_baseline_results_en_2</th>\n",
       "      <td>1056.152710</td>\n",
       "      <td>238.791077</td>\n",
       "      <td>142.295715</td>\n",
       "      <td>128.062286</td>\n",
       "      <td>154.608597</td>\n",
       "      <td>166.107605</td>\n",
       "      <td>1062.520630</td>\n",
       "      <td>1383.977783</td>\n",
       "      <td>541.564575</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean_baseline_results_sp_2</th>\n",
       "      <td>1056.152710</td>\n",
       "      <td>238.791077</td>\n",
       "      <td>142.295715</td>\n",
       "      <td>128.062286</td>\n",
       "      <td>154.608597</td>\n",
       "      <td>166.107605</td>\n",
       "      <td>1062.520630</td>\n",
       "      <td>1383.977783</td>\n",
       "      <td>541.564575</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean_baseline_results_it_0</th>\n",
       "      <td>1042.723511</td>\n",
       "      <td>307.813690</td>\n",
       "      <td>227.135864</td>\n",
       "      <td>132.740112</td>\n",
       "      <td>214.038010</td>\n",
       "      <td>56.357670</td>\n",
       "      <td>1298.071045</td>\n",
       "      <td>1209.288330</td>\n",
       "      <td>561.020996</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean_baseline_results_it_all</th>\n",
       "      <td>809.396179</td>\n",
       "      <td>386.337341</td>\n",
       "      <td>95.855042</td>\n",
       "      <td>57.547039</td>\n",
       "      <td>89.047768</td>\n",
       "      <td>67.882164</td>\n",
       "      <td>599.886963</td>\n",
       "      <td>362.396973</td>\n",
       "      <td>308.543701</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean_baseline_results_ge_0</th>\n",
       "      <td>826.836731</td>\n",
       "      <td>160.399002</td>\n",
       "      <td>103.260826</td>\n",
       "      <td>44.695576</td>\n",
       "      <td>92.703354</td>\n",
       "      <td>61.131493</td>\n",
       "      <td>1263.354736</td>\n",
       "      <td>1284.278442</td>\n",
       "      <td>479.582520</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean_baseline_results_ge_all</th>\n",
       "      <td>525.536926</td>\n",
       "      <td>243.086456</td>\n",
       "      <td>66.296516</td>\n",
       "      <td>98.677879</td>\n",
       "      <td>71.154892</td>\n",
       "      <td>106.976784</td>\n",
       "      <td>673.437134</td>\n",
       "      <td>412.632202</td>\n",
       "      <td>274.724823</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean_baseline_results_ge_1</th>\n",
       "      <td>542.562195</td>\n",
       "      <td>179.472336</td>\n",
       "      <td>56.266281</td>\n",
       "      <td>60.574272</td>\n",
       "      <td>62.516617</td>\n",
       "      <td>66.994057</td>\n",
       "      <td>813.093384</td>\n",
       "      <td>401.779327</td>\n",
       "      <td>272.907288</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                mse_loss0   mse_loss1   mse_loss2   mse_loss3  \\\n",
       "mean_baseline_results_ge_2     806.651550  343.989716   83.463081  132.983429   \n",
       "mean_baseline_results_en_1    1810.848999  274.370972  149.066116  168.991058   \n",
       "mean_baseline_results_sp_1    1810.848999  274.370972  149.066116  168.991058   \n",
       "mean_baseline_results_sp_0     811.969116  304.091217  217.723511  218.394775   \n",
       "mean_baseline_results_en_0     811.969116  304.091217  217.723511  218.394775   \n",
       "mean_baseline_results_en_all   640.336487  448.258118  100.318092   71.553055   \n",
       "mean_baseline_results_it_2     984.338318  389.863342   61.180115   36.295246   \n",
       "mean_baseline_results_it_1    2473.706543  266.036621  119.365463   87.648254   \n",
       "mean_baseline_results_sp_all   757.955078  360.768005  173.150589  188.085358   \n",
       "mean_baseline_results_en_2    1056.152710  238.791077  142.295715  128.062286   \n",
       "mean_baseline_results_sp_2    1056.152710  238.791077  142.295715  128.062286   \n",
       "mean_baseline_results_it_0    1042.723511  307.813690  227.135864  132.740112   \n",
       "mean_baseline_results_it_all   809.396179  386.337341   95.855042   57.547039   \n",
       "mean_baseline_results_ge_0     826.836731  160.399002  103.260826   44.695576   \n",
       "mean_baseline_results_ge_all   525.536926  243.086456   66.296516   98.677879   \n",
       "mean_baseline_results_ge_1     542.562195  179.472336   56.266281   60.574272   \n",
       "\n",
       "                               mse_loss4   mse_loss5    mse_loss6  \\\n",
       "mean_baseline_results_ge_2     84.457062  121.285454   651.978821   \n",
       "mean_baseline_results_en_1    254.935638  201.284912   563.093567   \n",
       "mean_baseline_results_sp_1    254.935638  201.284912   563.093567   \n",
       "mean_baseline_results_sp_0    229.068481  264.102142   449.343048   \n",
       "mean_baseline_results_en_0    229.068481  264.102142   449.343048   \n",
       "mean_baseline_results_en_all  116.193436   89.375259   273.781036   \n",
       "mean_baseline_results_it_2     59.142437   63.611099   746.830872   \n",
       "mean_baseline_results_it_1    209.708557   83.170052   452.522308   \n",
       "mean_baseline_results_sp_all  193.072662  268.179321   382.582245   \n",
       "mean_baseline_results_en_2    154.608597  166.107605  1062.520630   \n",
       "mean_baseline_results_sp_2    154.608597  166.107605  1062.520630   \n",
       "mean_baseline_results_it_0    214.038010   56.357670  1298.071045   \n",
       "mean_baseline_results_it_all   89.047768   67.882164   599.886963   \n",
       "mean_baseline_results_ge_0     92.703354   61.131493  1263.354736   \n",
       "mean_baseline_results_ge_all   71.154892  106.976784   673.437134   \n",
       "mean_baseline_results_ge_1     62.516617   66.994057   813.093384   \n",
       "\n",
       "                                mse_loss7  mse_loss_all  \n",
       "mean_baseline_results_ge_2     530.145752    344.369354  \n",
       "mean_baseline_results_en_1     598.750977    502.667816  \n",
       "mean_baseline_results_sp_1     598.750977    502.667816  \n",
       "mean_baseline_results_sp_0     713.752563    401.055634  \n",
       "mean_baseline_results_en_0     713.752563    401.055634  \n",
       "mean_baseline_results_en_all   289.469513    253.660629  \n",
       "mean_baseline_results_it_2     433.831909    346.886658  \n",
       "mean_baseline_results_it_1    1166.272705    607.303833  \n",
       "mean_baseline_results_sp_all   512.253784    354.505920  \n",
       "mean_baseline_results_en_2    1383.977783    541.564575  \n",
       "mean_baseline_results_sp_2    1383.977783    541.564575  \n",
       "mean_baseline_results_it_0    1209.288330    561.020996  \n",
       "mean_baseline_results_it_all   362.396973    308.543701  \n",
       "mean_baseline_results_ge_0    1284.278442    479.582520  \n",
       "mean_baseline_results_ge_all   412.632202    274.724823  \n",
       "mean_baseline_results_ge_1     401.779327    272.907288  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(res_mse).T"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d32f11c",
   "metadata": {},
   "source": [
    "## Finetuning Results\n",
    "\n",
    "### Not Pretraining"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7a2f8a78",
   "metadata": {},
   "outputs": [],
   "source": [
    "mapping_columns_names = {\n",
    "    0 : \"MSE\",\n",
    "    1 : \"Avg-Acc\",\n",
    "    2 : \"prob-skip-Acc\",\n",
    "    3 : \"firstfix-dur-Acc\",\n",
    "    4 : \"firstrun-dur-Acc\",\n",
    "    5 : \"dur-Acc\",\n",
    "    6 : \"firstrun-nfix-Acc\",\n",
    "    7 : \"nfix-Acc\",\n",
    "    8 : \"prob-refix-Acc\",\n",
    "    9 : \"prob-reread-Acc\",\n",
    "}\n",
    "\n",
    "def process_to_present(res, column_width=\"1.1cm\", plot_transpose=True):\n",
    "    df_res = pd.DataFrame.from_dict(res).T\n",
    "    df_res.iloc[:, 1:10]  = 100 - df_res.iloc[:, 1:10]\n",
    "    df_res = df_res.rename(columns=mapping_columns_names)\n",
    "    if not plot_transpose:\n",
    "        df_res = df_res.T\n",
    "    s = df_res.style\n",
    "    s.format(na_rep='MISS', precision=1)\n",
    "    print(s.to_latex(column_format='l'+('p{'+f'{column_width}'+'}')*len(df_res.columns)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d9cb1354",
   "metadata": {},
   "outputs": [],
   "source": [
    "res_ = collect_losses(\"../finetuning/notpretraining\")\n",
    "\n",
    "res = dict()\n",
    "\n",
    "for k, v in res_.items():\n",
    "    res[\" \".join(k.split(\"_\")[-3:-1])] = v[0]\n",
    "    \n",
    "res = collections.OrderedDict(sorted(res.items()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2299daeb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\begin{tabular}{lp{1.1cm}p{1.1cm}p{1.1cm}p{1.1cm}p{1.1cm}p{1.1cm}p{1.1cm}p{1.1cm}p{1.1cm}p{1.1cm}}\n",
      " & MSE & Avg-Acc & prob-skip-Acc & firstfix-dur-Acc & firstrun-dur-Acc & dur-Acc & firstrun-nfix-Acc & nfix-Acc & prob-refix-Acc & prob-reread-Acc \\\\\n",
      "en all & 103.0 & 84.5 & 79.0 & 65.6 & 88.2 & 91.7 & 86.1 & 90.2 & 89.5 & 86.0 \\\\\n",
      "ge 0 & 164.1 & 85.2 & 83.3 & 81.0 & 92.6 & 96.3 & 92.2 & 95.4 & 73.5 & 67.1 \\\\\n",
      "ge 1 & 94.6 & 87.5 & 85.4 & 78.0 & 93.1 & 93.6 & 91.9 & 92.7 & 80.4 & 84.9 \\\\\n",
      "ge 2 & 98.8 & 86.8 & 80.4 & 81.8 & 91.4 & 91.5 & 90.1 & 91.2 & 84.5 & 83.5 \\\\\n",
      "ge all & 106.0 & 86.4 & 85.2 & 72.4 & 92.1 & 92.3 & 90.7 & 91.1 & 83.2 & 84.4 \\\\\n",
      "it 0 & 228.7 & 81.9 & 78.8 & 78.3 & 90.7 & 91.8 & 87.8 & 94.1 & 71.5 & 62.5 \\\\\n",
      "it 1 & 236.3 & 84.6 & 59.5 & 85.7 & 90.4 & 92.8 & 86.0 & 92.3 & 90.8 & 79.4 \\\\\n",
      "it 2 & 142.3 & 86.0 & 79.0 & 72.5 & 92.9 & 95.0 & 92.0 & 92.4 & 81.3 & 82.9 \\\\\n",
      "it all & 147.9 & 85.0 & 79.9 & 69.5 & 90.6 & 93.7 & 89.8 & 92.3 & 82.6 & 81.5 \\\\\n",
      "sp 0 & 175.7 & 81.4 & 76.6 & 76.1 & 84.2 & 87.2 & 80.0 & 84.0 & 85.3 & 77.9 \\\\\n",
      "sp 1 & 166.7 & 84.3 & 64.8 & 84.9 & 89.2 & 89.4 & 84.6 & 88.2 & 86.6 & 86.5 \\\\\n",
      "sp 2 & 226.7 & 80.5 & 75.4 & 79.4 & 87.7 & 90.7 & 86.0 & 89.1 & 77.9 & 57.8 \\\\\n",
      "sp all & 173.3 & 81.4 & 76.9 & 72.3 & 84.9 & 87.7 & 81.0 & 83.6 & 86.2 & 78.9 \\\\\n",
      "\\end{tabular}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "process_to_present(res)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12b9d9db",
   "metadata": {},
   "source": [
    "### Pretraining"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c9739712",
   "metadata": {},
   "outputs": [],
   "source": [
    "res_ = collect_losses(\"../finetuning/pretraining\")\n",
    "\n",
    "res = dict()\n",
    "\n",
    "for k,v in res_.items():\n",
    "    res[\" \".join(k.split(\"_\")[-3:-1])] = v[0]\n",
    "    \n",
    "res = collections.OrderedDict(sorted(res.items()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2a5bb238",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\begin{tabular}{lp{1.1cm}p{1.1cm}p{1.1cm}p{1.1cm}p{1.1cm}p{1.1cm}p{1.1cm}p{1.1cm}p{1.1cm}p{1.1cm}}\n",
      " & MSE & Avg-Acc & prob-skip-Acc & firstfix-dur-Acc & firstrun-dur-Acc & dur-Acc & firstrun-nfix-Acc & nfix-Acc & prob-refix-Acc & prob-reread-Acc \\\\\n",
      "en all & 120.0 & 83.0 & 77.2 & 62.1 & 86.7 & 90.7 & 84.3 & 89.0 & 89.2 & 84.9 \\\\\n",
      "ge 0 & 176.1 & 84.8 & 84.3 & 78.8 & 91.9 & 96.4 & 91.2 & 95.3 & 74.2 & 66.5 \\\\\n",
      "ge 1 & 107.4 & 86.5 & 85.2 & 74.6 & 92.2 & 92.8 & 90.5 & 91.8 & 80.1 & 84.4 \\\\\n",
      "ge 2 & 110.8 & 85.8 & 80.1 & 79.2 & 90.3 & 90.6 & 88.7 & 90.2 & 84.5 & 83.0 \\\\\n",
      "ge all & 122.6 & 85.1 & 84.7 & 68.7 & 90.9 & 91.2 & 89.0 & 89.9 & 82.9 & 83.5 \\\\\n",
      "it 0 & 249.8 & 81.3 & 79.6 & 76.2 & 89.9 & 91.3 & 86.2 & 93.8 & 71.8 & 61.6 \\\\\n",
      "it 1 & 245.2 & 84.8 & 60.3 & 85.7 & 90.5 & 93.0 & 86.0 & 92.5 & 91.0 & 79.8 \\\\\n",
      "it 2 & 158.6 & 85.2 & 78.4 & 69.7 & 92.2 & 94.6 & 91.1 & 91.8 & 81.1 & 82.4 \\\\\n",
      "it all & 168.3 & 83.8 & 79.0 & 66.3 & 89.6 & 93.1 & 88.5 & 91.6 & 82.1 & 80.4 \\\\\n",
      "sp 0 & 197.7 & 80.1 & 75.6 & 73.8 & 82.8 & 86.1 & 78.1 & 82.7 & 85.1 & 76.9 \\\\\n",
      "sp 1 & 177.7 & 84.0 & 64.0 & 84.3 & 88.9 & 89.1 & 84.0 & 87.9 & 86.8 & 87.0 \\\\\n",
      "sp 2 & 247.8 & 79.8 & 76.0 & 77.8 & 86.7 & 90.2 & 84.5 & 88.4 & 78.4 & 56.5 \\\\\n",
      "sp all & 197.1 & 80.0 & 75.5 & 69.6 & 83.4 & 86.6 & 79.0 & 82.3 & 85.8 & 77.6 \\\\\n",
      "\\end{tabular}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "process_to_present(res)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20b1b881",
   "metadata": {},
   "source": [
    "### Not Pretraining Not Full"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7abe7b64",
   "metadata": {},
   "outputs": [],
   "source": [
    "res_ = collect_losses(\"../finetuning/notpretraining_notfull\")\n",
    "\n",
    "res = dict()\n",
    "\n",
    "for k,v in res_.items():\n",
    "    res[\" \".join(k.split(\"_\")[-4:-2])] = v[0]\n",
    "    \n",
    "res = collections.OrderedDict(sorted(res.items()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2d7e8799",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\begin{tabular}{lp{1.1cm}p{1.1cm}p{1.1cm}p{1.1cm}p{1.1cm}p{1.1cm}p{1.1cm}p{1.1cm}p{1.1cm}p{1.1cm}}\n",
      " & MSE & Avg-Acc & prob-skip-Acc & firstfix-dur-Acc & firstrun-dur-Acc & dur-Acc & firstrun-nfix-Acc & nfix-Acc & prob-refix-Acc & prob-reread-Acc \\\\\n",
      "en all & 164.6 & 79.5 & 72.1 & 54.7 & 83.5 & 88.6 & 80.8 & 86.6 & 87.8 & 82.2 \\\\\n",
      "ge 0 & 213.6 & 83.1 & 83.7 & 73.7 & 89.9 & 95.8 & 89.1 & 94.6 & 72.8 & 65.2 \\\\\n",
      "ge 1 & 149.4 & 83.4 & 82.5 & 67.0 & 89.4 & 90.6 & 87.4 & 89.2 & 77.7 & 83.1 \\\\\n",
      "ge 2 & 151.6 & 82.9 & 76.8 & 73.4 & 87.3 & 88.1 & 85.4 & 87.6 & 83.3 & 81.6 \\\\\n",
      "ge all & 171.3 & 81.6 & 81.7 & 60.7 & 87.9 & 88.7 & 85.8 & 87.0 & 80.6 & 80.5 \\\\\n",
      "it 0 & 307.0 & 79.3 & 79.0 & 71.7 & 87.5 & 89.8 & 83.3 & 92.7 & 71.4 & 59.1 \\\\\n",
      "it 1 & 282.1 & 83.8 & 58.6 & 83.7 & 89.0 & 91.9 & 84.0 & 91.4 & 91.2 & 80.5 \\\\\n",
      "it 2 & 212.4 & 82.5 & 75.2 & 63.0 & 90.0 & 93.1 & 88.9 & 89.8 & 79.0 & 80.7 \\\\\n",
      "it all & 227.2 & 80.7 & 75.5 & 59.4 & 86.9 & 91.4 & 85.8 & 89.6 & 79.8 & 77.3 \\\\\n",
      "sp 0 & 256.7 & 77.0 & 71.5 & 69.2 & 79.3 & 83.6 & 74.0 & 79.6 & 83.9 & 74.5 \\\\\n",
      "sp 1 & 224.6 & 81.9 & 60.0 & 81.5 & 86.6 & 87.1 & 80.9 & 85.6 & 86.6 & 87.3 \\\\\n",
      "sp 2 & 301.6 & 77.8 & 75.0 & 74.4 & 84.3 & 88.7 & 82.0 & 86.8 & 78.3 & 53.0 \\\\\n",
      "sp all & 258.5 & 76.6 & 71.1 & 64.3 & 80.0 & 84.1 & 75.1 & 79.1 & 84.4 & 74.3 \\\\\n",
      "\\end{tabular}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "process_to_present(res)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f97fbc7e",
   "metadata": {},
   "source": [
    "### Pretraining Not Full"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b60a60ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "res_ = collect_losses(\"../finetuning/pretraining_notfull\")\n",
    "\n",
    "res = dict()\n",
    "\n",
    "for k,v in res_.items():\n",
    "    res[\" \".join(k.split(\"_\")[-4:-2])] = v[0]\n",
    "    \n",
    "res = collections.OrderedDict(sorted(res.items()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a2fb9a19",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\begin{tabular}{lp{1.1cm}p{1.1cm}p{1.1cm}p{1.1cm}p{1.1cm}p{1.1cm}p{1.1cm}p{1.1cm}p{1.1cm}p{1.1cm}}\n",
      " & MSE & Avg-Acc & prob-skip-Acc & firstfix-dur-Acc & firstrun-dur-Acc & dur-Acc & firstrun-nfix-Acc & nfix-Acc & prob-refix-Acc & prob-reread-Acc \\\\\n",
      "en all & 194.1 & 76.8 & 69.5 & 51.3 & 80.7 & 85.9 & 77.6 & 83.5 & 86.2 & 79.9 \\\\\n",
      "ge 0 & 244.4 & 81.7 & 85.4 & 70.2 & 87.1 & 94.0 & 86.0 & 92.0 & 73.7 & 64.9 \\\\\n",
      "ge 1 & 181.8 & 81.0 & 82.1 & 63.2 & 86.3 & 87.6 & 83.9 & 85.7 & 77.0 & 82.3 \\\\\n",
      "ge 2 & 184.1 & 80.8 & 76.3 & 69.8 & 84.4 & 85.2 & 82.0 & 84.2 & 83.7 & 80.9 \\\\\n",
      "ge all & 208.1 & 78.8 & 80.5 & 56.8 & 84.7 & 85.6 & 82.2 & 83.4 & 79.2 & 78.2 \\\\\n",
      "it 0 & 344.0 & 77.9 & 79.9 & 68.9 & 85.3 & 87.6 & 80.7 & 90.3 & 71.8 & 58.4 \\\\\n",
      "it 1 & 306.8 & 84.0 & 59.1 & 83.1 & 88.5 & 91.4 & 83.3 & 90.8 & 93.4 & 82.1 \\\\\n",
      "it 2 & 244.7 & 80.8 & 75.1 & 60.0 & 87.8 & 91.1 & 86.2 & 87.2 & 78.7 & 80.0 \\\\\n",
      "it all & 263.8 & 78.6 & 74.5 & 56.2 & 84.4 & 89.1 & 82.9 & 86.8 & 78.9 & 75.7 \\\\\n",
      "sp 0 & 296.3 & 74.9 & 70.6 & 66.0 & 76.8 & 81.1 & 71.0 & 76.6 & 83.9 & 73.4 \\\\\n",
      "sp 1 & 252.6 & 81.4 & 59.8 & 79.9 & 85.4 & 85.8 & 79.4 & 84.1 & 88.4 & 88.8 \\\\\n",
      "sp 2 & 337.7 & 76.4 & 75.8 & 71.8 & 82.2 & 86.7 & 79.4 & 84.3 & 79.3 & 52.1 \\\\\n",
      "sp all & 299.3 & 74.3 & 69.7 & 61.0 & 77.4 & 81.5 & 72.0 & 76.0 & 84.0 & 72.5 \\\\\n",
      "\\end{tabular}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "process_to_present(res)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a02115d",
   "metadata": {},
   "source": [
    "### Not Pretraining Dur"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "5e5a5858",
   "metadata": {},
   "outputs": [],
   "source": [
    "res_ = collect_losses(\"../finetuning/notpretraining_dur\")\n",
    "\n",
    "res = dict()\n",
    "\n",
    "for k,v in res_.items():\n",
    "    res[\" \".join(k.split(\"_\")[-4:-2])] = v[0][:-1]\n",
    "    \n",
    "res = collections.OrderedDict(sorted(res.items()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "afdae6d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\begin{tabular}{lp{1cm}p{1cm}p{1cm}p{1cm}p{1cm}p{1cm}p{1cm}p{1cm}p{1cm}p{1cm}p{1cm}p{1cm}p{1cm}}\n",
      " & en all & ge 0 & ge 1 & ge 2 & ge all & it 0 & it 1 & it 2 & it all & sp 0 & sp 1 & sp 2 & sp all \\\\\n",
      "MSE & 15.4 & 12.1 & 16.5 & 26.4 & 19.3 & 33.2 & 34.1 & 12.6 & 14.9 & 51.2 & 43.7 & 29.7 & 41.5 \\\\\n",
      "Avg-Acc & 94.7 & 96.2 & 95.0 & 93.3 & 94.5 & 92.9 & 92.8 & 96.0 & 95.5 & 91.0 & 91.4 & 92.7 & 91.7 \\\\\n",
      "\\end{tabular}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "process_to_present(res, \"1cm\", False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f020df5",
   "metadata": {},
   "source": [
    "### Pretraining Dur"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "eba12441",
   "metadata": {},
   "outputs": [],
   "source": [
    "res_ = collect_losses(\"../finetuning/pretraining_dur\")\n",
    "\n",
    "res = dict()\n",
    "\n",
    "for k,v in res_.items():\n",
    "    res[\" \".join(k.split(\"_\")[-4:-2])] = v[0][:-1]\n",
    "    \n",
    "res = collections.OrderedDict(sorted(res.items()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e0abc8cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\begin{tabular}{lp{1cm}p{1cm}p{1cm}p{1cm}p{1cm}p{1cm}p{1cm}p{1cm}p{1cm}p{1cm}p{1cm}p{1cm}p{1cm}}\n",
      " & en all & ge 0 & ge 1 & ge 2 & ge all & it 0 & it 1 & it 2 & it all & sp 0 & sp 1 & sp 2 & sp all \\\\\n",
      "MSE & 15.8 & 9.7 & 14.6 & 26.0 & 18.9 & 31.2 & 27.9 & 9.7 & 12.2 & 62.3 & 44.7 & 30.9 & 51.7 \\\\\n",
      "Avg-Acc & 95.0 & 96.7 & 95.7 & 93.7 & 95.0 & 93.5 & 93.8 & 96.9 & 96.2 & 90.2 & 91.7 & 92.9 & 90.9 \\\\\n",
      "\\end{tabular}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "process_to_present(res, \"1cm\", False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0673571f",
   "metadata": {},
   "source": [
    "### Not Pretraining Prob Skip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "aaa0b15a",
   "metadata": {},
   "outputs": [],
   "source": [
    "res_ = collect_losses(\"../finetuning/notpretraining_prob_skip\")\n",
    "\n",
    "res = dict()\n",
    "\n",
    "for k,v in res_.items():\n",
    "    res[\" \".join(k.split(\"_\")[-5:-3])] = v[0][:-1]\n",
    "    \n",
    "res = collections.OrderedDict(sorted(res.items()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "dcb3c9e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\begin{tabular}{lp{1cm}p{1cm}p{1cm}p{1cm}p{1cm}p{1cm}p{1cm}p{1cm}p{1cm}p{1cm}p{1cm}p{1cm}p{1cm}}\n",
      " & en all & ge 0 & ge 1 & ge 2 & ge all & it 0 & it 1 & it 2 & it all & sp 0 & sp 1 & sp 2 & sp all \\\\\n",
      "MSE & 147.2 & 200.6 & 107.0 & 199.4 & 102.9 & 270.9 & 861.4 & 302.4 & 248.6 & 267.8 & 579.5 & 316.0 & 249.7 \\\\\n",
      "Avg-Acc & 79.8 & 84.7 & 86.5 & 77.6 & 86.2 & 80.6 & 55.4 & 74.8 & 77.2 & 74.5 & 61.2 & 70.9 & 75.3 \\\\\n",
      "\\end{tabular}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "process_to_present(res, \"1cm\", False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf7ce4d2",
   "metadata": {},
   "source": [
    "### Pretraining Prob Skip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "bb1c92a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "res_ = collect_losses(\"../finetuning/pretraining_prob_skip\")\n",
    "\n",
    "res = dict()\n",
    "\n",
    "for k,v in res_.items():\n",
    "    res[\" \".join(k.split(\"_\")[-5:-3])] = v[0][:-1]\n",
    "    \n",
    "res = collections.OrderedDict(sorted(res.items()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "87cd019b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\begin{tabular}{lp{1cm}p{1cm}p{1cm}p{1cm}p{1cm}p{1cm}p{1cm}p{1cm}p{1cm}p{1cm}p{1cm}p{1cm}p{1cm}}\n",
      " & en all & ge 0 & ge 1 & ge 2 & ge all & it 0 & it 1 & it 2 & it all & sp 0 & sp 1 & sp 2 & sp all \\\\\n",
      "MSE & 175.2 & 199.0 & 110.4 & 200.0 & 107.6 & 285.9 & 976.6 & 306.2 & 259.9 & 288.9 & 641.5 & 331.0 & 273.0 \\\\\n",
      "Avg-Acc & 79.4 & 85.4 & 87.3 & 82.3 & 87.0 & 81.6 & 60.8 & 79.9 & 80.4 & 77.5 & 65.0 & 77.4 & 77.5 \\\\\n",
      "\\end{tabular}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "process_to_present(res, \"1cm\", False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml-meco",
   "language": "python",
   "name": "ml-meco"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
